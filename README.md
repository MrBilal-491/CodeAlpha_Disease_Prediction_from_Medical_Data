# CodeAlpha_Disease_Prediction_from_Medical_Data
The main goal of this project is to develop a disease prediction model using structured patient data such as test results, demographic information, and medical features. By leveraging machine learning, we aim to predict the presence or absence of a disease, thereby assisting in early diagnosis and better treatment planning.
Dataset Description
For this study, we used the Breast Cancer Wisconsin Diagnostic Dataset, which is a well-known and publicly available dataset in the sklearn.datasets library. It contains 569 patient records with 30 real-valued features derived from digital images of fine needle aspirates (FNA) of breast masses.
üîë Key Features:
‚Ä¢	Radius (mean of distances from center to points on the perimeter)
‚Ä¢	Texture (standard deviation of gray-scale values)
‚Ä¢	Perimeter, Area, Smoothness, Compactness, Concavity, Symmetry
‚Ä¢	‚Ä¶and other domain-specific features.
üéØ Target Labels:
‚Ä¢	0: Malignant (cancerous)
‚Ä¢	1: Benign (non-cancerous)
________________________________________
Approach
To solve this classification problem, the pipeline follows these steps:
1. Data Preprocessing
‚Ä¢	Train-Test Split: The dataset is divided into training and testing sets (80/20).
‚Ä¢	Feature Scaling: Standardization is applied to normalize features for algorithms that are sensitive to scale (e.g., SVM, Logistic Regression).
2. Model Training
We apply four supervised machine learning classification algorithms:
________________________________________
üîç Algorithms Used
1. Logistic Regression
‚Ä¢	A statistical model used for binary classification.
‚Ä¢	Models the probability that a given input point belongs to a particular class.
‚Ä¢	Output is interpreted using the sigmoid function, which maps values between 0 and 1.
2. Support Vector Machine (SVM)
‚Ä¢	SVM creates a hyperplane that best separates the classes in the feature space.
‚Ä¢	It is effective in high-dimensional spaces and works well when the margin between classes is clear.
‚Ä¢	We used the variant that supports probability estimation.
3. Random Forest
‚Ä¢	An ensemble method based on Decision Trees.
‚Ä¢	It creates a large number of trees during training and outputs the mode of the classes.
‚Ä¢	Excellent for handling overfitting and non-linear relationships.
4. XGBoost (Extreme Gradient Boosting)
‚Ä¢	A highly efficient and accurate implementation of gradient boosting.
‚Ä¢	It builds trees sequentially, where each new tree corrects the errors made by previous ones.
‚Ä¢	Known for its speed and accuracy, especially in structured data.
